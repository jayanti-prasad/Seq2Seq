{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad7e936-4253-4410-a3c5-181b0a886376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder-Input-Layer (Input  [(None, None, 210)]       0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " Encoder-LSTM-Layer (LSTM)   [(None, 60),              65040     \n",
      "                              (None, 60),                        \n",
      "                              (None, 60)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65040 (254.06 KB)\n",
      "Trainable params: 65040 (254.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Decoder-Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Decoder-Input-Layer (Input  [(None, None, 172)]          0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 60)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)       [(None, 60)]                 0         []                            \n",
      "                                                                                                  \n",
      " Decoder-LSTM-Layer (LSTM)   [(None, None, 60),           55920     ['Decoder-Input-Layer[0][0]', \n",
      "                              (None, 60),                            'input_21[0][0]',            \n",
      "                              (None, 60)]                            'input_22[0][0]']            \n",
      "                                                                                                  \n",
      " Decoder-Dense-Layer (Dense  (None, None, 172)            10492     ['Decoder-LSTM-Layer[1][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66412 (259.42 KB)\n",
      "Trainable params: 66412 (259.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "h= [[ 0.4264402   0.38739714  0.40164906  0.83197296 -0.4154713  -0.5840464\n",
      "  -0.28939176 -0.5455271  -0.6252776  -0.8180439  -0.8654854   0.18055281\n",
      "   0.22526264 -0.00902024  0.48956355 -0.34840935 -0.6203704   0.15230823\n",
      "  -0.46720994 -0.22743535  0.8205785   0.5907891  -0.6271179  -0.8779664\n",
      "  -0.36722907 -0.30411798  0.80191815  0.42009783  0.24196051 -0.5700054\n",
      "   0.65638417  0.29963142  0.6051374   0.58764327 -0.74131304  0.8413576\n",
      "  -0.49426916 -0.2994285  -0.4478906  -0.5645994   0.7585894  -0.6382756\n",
      "  -0.59627753 -0.630536    0.44441438  0.79800427  0.37842643  0.8160204\n",
      "   0.41640234 -0.85930216  0.40391347 -0.4946335   0.18309234  0.47117522\n",
      "   0.51182956 -0.03595839  0.5886685   0.5244865  -0.41987282  0.04221337]\n",
      " [ 0.7423947   0.642937    0.68593407  0.95245844 -0.67714316 -0.7768382\n",
      "  -0.5804599  -0.81514    -0.8409896  -0.92430544 -0.96351916  0.7532289\n",
      "   0.22577722 -0.08023683  0.67105794 -0.62746197 -0.368511    0.46163997\n",
      "  -0.68941945 -0.5187976   0.93520933  0.86129993 -0.68626994 -0.940804\n",
      "  -0.53942066 -0.7196447   0.7663551   0.64344215  0.25174367 -0.83341\n",
      "   0.8412158  -0.12588081  0.77295035  0.8324382  -0.8990625   0.86905646\n",
      "  -0.7794633  -0.7718472  -0.7156679  -0.78557044  0.87697214 -0.83399063\n",
      "  -0.8034875  -0.8390759   0.7783029   0.94792324  0.62318766  0.8988169\n",
      "   0.6897771  -0.8426902   0.7374285  -0.76210374  0.10573068  0.7569136\n",
      "   0.39785227  0.24849433  0.78236455  0.6934928  -0.7497366   0.45296612]\n",
      " [ 0.76684904  0.63628775  0.71182466  0.9405978  -0.6833736  -0.76237875\n",
      "  -0.39413646 -0.7172162  -0.8254417  -0.92172945 -0.9399076   0.58470625\n",
      "   0.02851547 -0.07137358  0.6464154  -0.67591155  0.53807163  0.65828556\n",
      "  -0.730704   -0.56398505  0.8994803   0.76945555  0.18012397 -0.65143394\n",
      "  -0.54968727 -0.7318947   0.64313227  0.6727632   0.13669315 -0.7892157\n",
      "   0.8180206   0.10785713  0.73601794  0.7324071  -0.8728476   0.7538195\n",
      "  -0.767469   -0.7525655  -0.72732663 -0.7767727   0.80103374 -0.8102407\n",
      "  -0.7859056  -0.7944193   0.72528815  0.9055911   0.65889704  0.27072182\n",
      "   0.6681056  -0.67619026  0.7386114  -0.7374838   0.01495075  0.7373418\n",
      "  -0.35954258  0.3617506   0.76925427  0.31339863 -0.70398235  0.3502296 ]\n",
      " [ 0.7358751   0.6374758   0.6825523   0.9559215  -0.6609105  -0.777263\n",
      "  -0.62046695 -0.85030335 -0.84272677 -0.92511994 -0.9677809   0.80302703\n",
      "   0.26691076 -0.09886354  0.67559195 -0.6151888  -0.58038574  0.3739619\n",
      "  -0.67922497 -0.5055658   0.94061494  0.8833726  -0.77166754 -0.9567125\n",
      "  -0.5280492  -0.704932    0.7817401   0.6392222   0.2902253  -0.8402294\n",
      "   0.8449668  -0.31846967  0.7797879   0.861628   -0.9013004   0.8483582\n",
      "  -0.7756865  -0.7856833  -0.7078788  -0.78897053  0.89028484 -0.8387117\n",
      "  -0.80484754 -0.8444799   0.80032104  0.9564049   0.6185055   0.9304655\n",
      "   0.69913197 -0.8638658   0.7450819  -0.76613754  0.1262725   0.7588182\n",
      "   0.5673382   0.22807264  0.7855538   0.73819315 -0.75559723  0.5165886 ]]\n",
      "target_seq: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]]\n",
      "staes_value= [[ 0.4264402   0.38739714  0.40164906  0.83197296 -0.4154713  -0.5840464\n",
      "  -0.28939176 -0.5455271  -0.6252776  -0.8180439  -0.8654854   0.18055281\n",
      "   0.22526264 -0.00902024  0.48956355 -0.34840935 -0.6203704   0.15230823\n",
      "  -0.46720994 -0.22743535  0.8205785   0.5907891  -0.6271179  -0.8779664\n",
      "  -0.36722907 -0.30411798  0.80191815  0.42009783  0.24196051 -0.5700054\n",
      "   0.65638417  0.29963142  0.6051374   0.58764327 -0.74131304  0.8413576\n",
      "  -0.49426916 -0.2994285  -0.4478906  -0.5645994   0.7585894  -0.6382756\n",
      "  -0.59627753 -0.630536    0.44441438  0.79800427  0.37842643  0.8160204\n",
      "   0.41640234 -0.85930216  0.40391347 -0.4946335   0.18309234  0.47117522\n",
      "   0.51182956 -0.03595839  0.5886685   0.5244865  -0.41987282  0.04221337]\n",
      " [ 0.7423947   0.642937    0.68593407  0.95245844 -0.67714316 -0.7768382\n",
      "  -0.5804599  -0.81514    -0.8409896  -0.92430544 -0.96351916  0.7532289\n",
      "   0.22577722 -0.08023683  0.67105794 -0.62746197 -0.368511    0.46163997\n",
      "  -0.68941945 -0.5187976   0.93520933  0.86129993 -0.68626994 -0.940804\n",
      "  -0.53942066 -0.7196447   0.7663551   0.64344215  0.25174367 -0.83341\n",
      "   0.8412158  -0.12588081  0.77295035  0.8324382  -0.8990625   0.86905646\n",
      "  -0.7794633  -0.7718472  -0.7156679  -0.78557044  0.87697214 -0.83399063\n",
      "  -0.8034875  -0.8390759   0.7783029   0.94792324  0.62318766  0.8988169\n",
      "   0.6897771  -0.8426902   0.7374285  -0.76210374  0.10573068  0.7569136\n",
      "   0.39785227  0.24849433  0.78236455  0.6934928  -0.7497366   0.45296612]\n",
      " [ 0.76684904  0.63628775  0.71182466  0.9405978  -0.6833736  -0.76237875\n",
      "  -0.39413646 -0.7172162  -0.8254417  -0.92172945 -0.9399076   0.58470625\n",
      "   0.02851547 -0.07137358  0.6464154  -0.67591155  0.53807163  0.65828556\n",
      "  -0.730704   -0.56398505  0.8994803   0.76945555  0.18012397 -0.65143394\n",
      "  -0.54968727 -0.7318947   0.64313227  0.6727632   0.13669315 -0.7892157\n",
      "   0.8180206   0.10785713  0.73601794  0.7324071  -0.8728476   0.7538195\n",
      "  -0.767469   -0.7525655  -0.72732663 -0.7767727   0.80103374 -0.8102407\n",
      "  -0.7859056  -0.7944193   0.72528815  0.9055911   0.65889704  0.27072182\n",
      "   0.6681056  -0.67619026  0.7386114  -0.7374838   0.01495075  0.7373418\n",
      "  -0.35954258  0.3617506   0.76925427  0.31339863 -0.70398235  0.3502296 ]\n",
      " [ 0.7358751   0.6374758   0.6825523   0.9559215  -0.6609105  -0.777263\n",
      "  -0.62046695 -0.85030335 -0.84272677 -0.92511994 -0.9677809   0.80302703\n",
      "   0.26691076 -0.09886354  0.67559195 -0.6151888  -0.58038574  0.3739619\n",
      "  -0.67922497 -0.5055658   0.94061494  0.8833726  -0.77166754 -0.9567125\n",
      "  -0.5280492  -0.704932    0.7817401   0.6392222   0.2902253  -0.8402294\n",
      "   0.8449668  -0.31846967  0.7797879   0.861628   -0.9013004   0.8483582\n",
      "  -0.7756865  -0.7856833  -0.7078788  -0.78897053  0.89028484 -0.8387117\n",
      "  -0.80484754 -0.8444799   0.80032104  0.9564049   0.6185055   0.9304655\n",
      "   0.69913197 -0.8638658   0.7450819  -0.76613754  0.1262725   0.7588182\n",
      "   0.5673382   0.22807264  0.7855538   0.73819315 -0.75559723  0.5165886 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,1,172) (4,60) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 167\u001b[0m\n\u001b[0;32m    163\u001b[0m            encoder_in_data[i, j, token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder_in_data)\n\u001b[1;32m--> 167\u001b[0m \u001b[43mI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_in_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 104\u001b[0m, in \u001b[0;36mInfr_model.predict\u001b[1;34m(self, inp_vecs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_seq:\u001b[39m\u001b[38;5;124m\"\u001b[39m,target_seq)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaes_value=\u001b[39m\u001b[38;5;124m\"\u001b[39m,states_value)\n\u001b[1;32m--> 104\u001b[0m output_tokens, h, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43m[\u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates_value\u001b[49m)\n\u001b[0;32m    105\u001b[0m preds  \u001b[38;5;241m=\u001b[39m  output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m#preds  = [preds[i] / dec_prob[i] for i in range (0, len (preds))]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,1,172) (4,60) "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model \n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def get_lookup (df):\n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    count = 0\n",
    "    prob = []\n",
    "    counts = df['count'].to_list()\n",
    "    norm = np.sum (counts)\n",
    "    prob = [p /norm for p in counts]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        token2id [row['word']] = count\n",
    "        id2token [count] = row['word']\n",
    "        count+=1\n",
    "    return token2id, id2token, prob      \n",
    "\n",
    "\n",
    "def text2vec (input_text, df_vocab, vocab_size, vec_len):\n",
    "    D = df_vocab.iloc[:vocab_size]\n",
    "    ids = [i for i in range (0, len (D))]\n",
    "    D = D.assign (id=ids)\n",
    "    D.index = D['word'].to_list()\n",
    "    text_vecs = []\n",
    "    for text in input_text:\n",
    "        words = text.split(\" \")\n",
    "        words = [w for w in words if w in D.index]\n",
    "        vec = [D.loc[w]['id'] for w in words]\n",
    "        # do padding \n",
    "        if len (vec) > vec_len:\n",
    "            vec = vec[:vec_len]\n",
    "        if len (vec) < vec_len:\n",
    "            vec = vec + [0] * (vec_len - len(vec))\n",
    "        text_vecs.append (vec)\n",
    "    return np.array (text_vecs)     \n",
    "\n",
    "\n",
    "class Infr_model :\n",
    "    def __init__(self, model_path, num_input_tokens, num_output_tokens, latent_dim, vocab_in, vocab_out):\n",
    "        self.model_path = model_path \n",
    "        self.latent_dim = latent_dim \n",
    "        self.num_input_tokens  = num_input_tokens\n",
    "        self.num_output_tokens = num_output_tokens \n",
    "        self.model = load_model(model_path)\n",
    "        self.vocab_in = vocab_in \n",
    "        self.vocab_out = vocab_out \n",
    "\n",
    "       # Get the encoder model \n",
    "        encoder_inputs = Input(shape=(None, num_input_tokens),name='Encoder-Input-Layer')\n",
    "        encoder_lstm = self.model.get_layer('Encoder-LSTM-Layer')\n",
    "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "        self.encoder_model  = Model (encoder_inputs, encoder_outputs)\n",
    "\n",
    "        print(self.encoder_model.summary())\n",
    "               \n",
    "        decoder_inputs = Input(shape=(None, num_output_tokens),name='Decoder-Input-Layer')\n",
    "        \n",
    "        decoder_state_input_h = Input(shape=(self.latent_dim,))\n",
    "        decoder_state_input_c = Input(shape=(self.latent_dim,))\n",
    "\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_lstm = self.model.get_layer ('Decoder-LSTM-Layer')\n",
    "        decoder_dense = self.model.get_layer ('Decoder-Dense-Layer')\n",
    "        \n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states, name='Decoder-Model')\n",
    "        \n",
    "        print(self.decoder_model.summary())\n",
    "        \n",
    "    def predict (self, inp_vecs):\n",
    "        max_decoder_seq_len = 10 \n",
    "\n",
    "        enc_token2id, enc_id2token, enc_prob = get_lookup (self.vocab_in)\n",
    "        dec_token2id, dec_id2token, dec_prob = get_lookup (self.vocab_out)\n",
    "     \n",
    "        dec_token2id['__START__'] = 1\n",
    "          \n",
    "        states_value = self.encoder_model.predict(inp_vecs)\n",
    "        print(\"h=\",states_value) \n",
    "        \n",
    "        #Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1, self.num_output_tokens))\n",
    "\n",
    "        #Get the first character of target sequence with the start character.\n",
    "        target_seq[0, dec_token2id['__START__']] = 1.\n",
    "\n",
    "        #Sampling loop for a batch of sequences\n",
    "        #(to simplify, here we assume a batch of size 1).\n",
    "    \n",
    "        stop_condition = False\n",
    "        decoded_sentence = ' '\n",
    "    \n",
    "        while not stop_condition:\n",
    "            print(\"target_seq:\",target_seq)\n",
    "            print(\"staes_value=\",states_value)\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "            preds  =  output_tokens[0, 0,:]\n",
    "            #preds  = [preds[i] / dec_prob[i] for i in range (0, len (preds))]\n",
    "            print(\"preds=\",preds)\n",
    "        \n",
    "            #Sample a token\n",
    "            sampled_token_index = np.argmax(preds)\n",
    "        \n",
    "            sampled_word = dec_id2token[sampled_token_index]\n",
    "            #if sampled_word not in decoded_sentence.split(\" \") or np.random.random([10])[0] > 0.25:  \n",
    "            #    decoded_sentence = decoded_sentence + \"  \" +  sampled_word\n",
    "            #print(\"decoced sent:\",decoded_sentence)\n",
    "\n",
    "            #if len(decoded_sentence.split(\" \")) > max_decoder_seq_len :\n",
    "            #    stop_condition = True \n",
    "            #if sampled_word == '__STOP__':\n",
    "            #    stop_condition = True \n",
    "            #Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "            #Update states\n",
    "            states_value = [h, c]\n",
    "   \n",
    "        return decoded_sentence  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "     root_path = r\"C:\\Users\\jayanti.prasad\\Projects-Dev\\Seq2Seq\\tmp\"\n",
    "     model_path = r\"C:\\Users\\jayanti.prasad\\Projects-Dev\\Seq2Seq\\tmp\\trained_model\\model.hdf5\"\n",
    "     df = pd.read_csv(r\"C:\\Users\\jayanti.prasad\\Data\\NLP_DATA\\seq2seq_data\\english-french-sentence-pairs.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "     num_input_tokens = 210\n",
    "     num_output_tokens = 172\n",
    "     latent_dim = 60 \n",
    "\n",
    "     df_inp = pd.read_csv (root_path + os.sep +\"vocab_inp.csv\",encoding='utf-8')\n",
    "     df_out = pd.read_csv (root_path + os.sep + \"vocab_out.csv\", encoding='utf-8')\n",
    "\n",
    "     df_inp = df_inp [df_inp ['count'] > 10]\n",
    "     df_out = df_out [df_out ['count'] > 10] \n",
    "    \n",
    "     I = Infr_model (model_path, num_input_tokens, num_output_tokens, latent_dim, df_inp, df_out) \n",
    "\n",
    "     texts = []\n",
    "     for i in  [11,56, 87, 98]:\n",
    "         text = df.iloc[i]['en']\n",
    "         texts.append (text)\n",
    "\n",
    "     input_vecs = text2vec (texts, df_inp, num_input_tokens, 8 )\n",
    "\n",
    "     encoder_in_data = np.zeros((len(input_vecs), 8, num_input_tokens), dtype='float32')\n",
    "\n",
    "\n",
    "     for i in range (0, len (input_vecs)):\n",
    "           for j, token_id in enumerate (input_vecs[i]):\n",
    "                encoder_in_data[i, j, token_id] = 1\n",
    "    \n",
    "     print(encoder_in_data)\n",
    "    \n",
    "     I.predict (encoder_in_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dc764-0328-4dc8-a71f-a96a0b1b06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
