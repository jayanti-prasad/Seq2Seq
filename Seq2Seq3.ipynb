{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', \"'\", ',', '.', '0', '2', '?', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['\\t', '\\n', ' ', '!', '(', ')', ',', '.', '0', '2', '?', 'C', 'D', 'அ', 'ஆ', 'இ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', '்']\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, None, 53)]   0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None, None, 54)]   0           []                               \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 [(None, 256),        317440      ['input_45[0][0]']               \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)                 [(None, None, 256),  318464      ['input_46[0][0]',               \n",
      "                                 (None, 256),                     'lstm_22[0][1]',                \n",
      "                                 (None, 256)]                     'lstm_22[0][2]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, None, 54)     13878       ['lstm_23[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 649,782\n",
      "Trainable params: 649,782\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, None, 53)]   0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None, None, 54)]   0           []                               \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 [(None, 256),        317440      ['input_45[0][0]']               \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)                 [(None, None, 256),  318464      ['input_46[0][0]',               \n",
      "                                 (None, 256),                     'lstm_22[0][1]',                \n",
      "                                 (None, 256)]                     'lstm_22[0][2]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, None, 54)     13878       ['lstm_23[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 649,782\n",
      "Trainable params: 649,782\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "encoder_in_data shape: (207, 94, 53)\n",
      "decoder_in_data shape: (207, 111, 54)\n",
      "decoder_target_data shape: (207, 111, 54)\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 9s 1s/step - loss: 1.0252 - val_loss: 1.5902\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 2s 850ms/step - loss: 0.9091 - val_loss: 1.5341\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.8692 - val_loss: 1.5699\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 0.8723 - val_loss: 1.5275\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 2s 728ms/step - loss: 0.8412 - val_loss: 1.5024\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 2s 805ms/step - loss: 0.8334 - val_loss: 1.4914\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 2s 812ms/step - loss: 0.8286 - val_loss: 1.4884\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8288 - val_loss: 1.4895\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 3s 943ms/step - loss: 0.8242 - val_loss: 1.4835\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 3s 999ms/step - loss: 0.8136 - val_loss: 1.4806\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8186 - val_loss: 1.4857\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8193 - val_loss: 1.4765\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8116 - val_loss: 1.4777\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8052 - val_loss: 1.4664\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.7951 - val_loss: 1.4680\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFlCAYAAADYnoD9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyKklEQVR4nO3deXxU9b3/8ddnJvsGSQiLhLAoi8huhCouUJdStVC3VrRVqnWrS/W2V21/rVqXW3vrvVVr1avW0sVirQtC3aUqVq2CyA4uIEIAIRBIAtmT7++PM0kmISEBZnKSyfv5eMxjzjbnfAaR93y/53vOMeccIiIi4p+A3wWIiIh0dwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ/F+XXgXr16uUGDBvl1eBERkQ734Ycf7nDO5TRf7lsYDxo0iMWLF/t1eBERkQ5nZl+0tFzd1CIiIj5TGIuIiPhMYSwiIuIz384Zi4hI26qrqykoKKCiosLvUuQAJCUlkZubS3x8fLu2VxiLiHRiBQUFpKenM2jQIMzM73KkHZxz7Ny5k4KCAgYPHtyuz7TZTW1mj5vZdjNbuZ9tppjZUjNbZWZvHUDNIiKyHxUVFWRnZyuIuxAzIzs7+4B6M9pzzng2MG0/B+0JPAhMd84dBZzX7qOLiEibFMRdz4H+N2szjJ1zC4Gi/WxyAfCsc25jaPvtB1SBiIh0Wjt37mTcuHGMGzeOvn370r9//4b5qqqq/X528eLFXHfddW0e47jjjotIrW+++SZnnnlmRPbV0SJxzngYEG9mbwLpwH3OuT9FYL8iIuKz7Oxsli5dCsBtt91GWloaP/7xjxvW19TUEBfXcpTk5+eTn5/f5jHefffdiNTalUXi0qY44GjgDOBrwM/NbFhLG5rZ5Wa22MwWFxYWRuDQIiLS0WbNmsWVV17JpEmTuPHGG/nggw849thjGT9+PMcddxwff/wx0LSletttt3HJJZcwZcoUhgwZwv3339+wv7S0tIbtp0yZwrnnnsuIESO48MILcc4B8OKLLzJixAiOPvporrvuugNqAc+ZM4fRo0czatQobrrpJgBqa2uZNWsWo0aNYvTo0fzmN78B4P7772fkyJGMGTOG888//9D/sNopEi3jAmCnc24vsNfMFgJjgU+ab+icewR4BCA/P99F4NgiIt3GL+avYvWWkojuc+RhGdz6jaMO+HMFBQW8++67BINBSkpKePvtt4mLi+P111/npz/9Kc8888w+n1m7di1vvPEGpaWlDB8+nKuuumqfS38++ugjVq1axWGHHcbkyZN55513yM/P54orrmDhwoUMHjyYmTNntrvOLVu2cNNNN/Hhhx+SmZnJaaedxty5cxkwYACbN29m5UpvbPLu3bsBuPvuu/n8889JTExsWNYRItEyfh443szizCwFmASsicB+26+uDlY87b2LiEjUnXfeeQSDQQCKi4s577zzGDVqFDfccAOrVq1q8TNnnHEGiYmJ9OrVi969e7Nt27Z9tpk4cSK5ubkEAgHGjRvHhg0bWLt2LUOGDGm4TOhAwnjRokVMmTKFnJwc4uLiuPDCC1m4cCFDhgxh/fr1XHvttbz88stkZGQAMGbMGC688EL+8pe/tNr9Hg1tHsnM5gBTgF5mVgDcCsQDOOceds6tMbOXgeVAHfCYc67Vy6CiYu0/4JlL4aO/wFkPQ3rfDj28iEhHOJgWbLSkpqY2TP/85z9n6tSpPPfcc2zYsIEpU6a0+JnExMSG6WAwSE1NzUFtEwmZmZksW7aMV155hYcffpinnnqKxx9/nBdeeIGFCxcyf/587rrrLlasWNEhodye0dQznXP9nHPxzrlc59zvQyH8cNg2v3bOjXTOjXLO3RvVilty5DfgG/fBxn/DQ8fBJ690eAkiIt1VcXEx/fv3B2D27NkR3//w4cNZv349GzZsAOBvf/tbuz87ceJE3nrrLXbs2EFtbS1z5szhpJNOYseOHdTV1XHOOedw5513smTJEurq6ti0aRNTp07lV7/6FcXFxezZsyfi36clsXEHLjM4ehbkHQtPXwp//RZMvAJOvR3ik/yuTkQkpt14441cfPHF3HnnnZxxxhkR339ycjIPPvgg06ZNIzU1lWOOOabVbRcsWEBubm7D/N///nfuvvtupk6dinOOM844gxkzZrBs2TK+973vURc6vfnLX/6S2tpavvOd71BcXIxzjuuuu46ePXtG/Pu0xOpHqnW0/Px8F5XnGVdXwIJfwL8fhD6j4JzfQ+8RkT+OiEgHWLNmDUceeaTfZfhuz549pKWl4Zzj6quvZujQodxwww1+l7VfLf23M7MPnXP7XO8Ve09tik+Cab+EC/4OpV/CI1Ng8ePg048OERE5dI8++ijjxo3jqKOOori4mCuuuMLvkiIq9lrG4Uq3wdwrYd0/YcSZMP23kJIV3WOKiESQWsZdV/duGYdL7wMXPgOn3eUN6npoMnz+tt9ViYiINBHbYQwQCMBx18D3X4eEFPjjN2DBHVBb7XdlB6a2xruW+rmrYL0ejCUiEktiYzR1exw2Di5/C16+Cd6+Bz5/C85+FLLa96xJ31Tt9a6ffu8B2L0Rgomw7K9wxKlw6i+gT+e57lBERA5O7LeMwyWmwYzfwbl/gMJP4OETYPnf/a6qZXt3wBv/Bb85Cl66EdIPg/PnwE0b4NQ7oOADr9t97tVQvNnvakVE5BB0rzCuN+psuOpfXqvy2e/Dc1dCZanfVXmK1sM//sML4bd+BQMnwyWvwqWvwIjTva72ydfBdUvh2KthxVPw2wnw+m1QUex39SISY6ZOncorrzS9kdK9997LVVdd1epnpkyZQv0A3dNPP73Fezzfdttt3HPPPfs99ty5c1m9enXD/C233MLrr79+ANW3rDM+arF7hjFAzzyY9QKcdDMs/5vXSt78oX/1bP4QnroYfns0fPRnGPMtuHoRnP8E5E3ad/uULPjaXXDNYhg5A/71G7hvHPz7Iaip7PDyRSQ2zZw5kyeffLLJsieffLLd94d+8cUXD/rGGc3D+Pbbb+eUU045qH11dt03jAGCcTD1J14o11bD70/zQq2jHjjhHHz6Osw+Ex79Kqx7Ayb/EK5f4V2GldPikyibyhwIZz/inQ/vOxpevhkeOEYPzhCRiDj33HN54YUXqKqqAmDDhg1s2bKFE044gauuuor8/HyOOuoobr311hY/P2jQIHbs2AHAXXfdxbBhwzj++OMbHrMI3jXExxxzDGPHjuWcc86hrKyMd999l3nz5vGf//mfjBs3jnXr1jFr1iyefvppwLvT1vjx4xk9ejSXXHIJlZWVDce79dZbmTBhAqNHj2bt2rXt/q5+Pmqx+wzg2p+Bx3nd1vOv97p71/0TznoEMvpF53i11bDyGXjnfti+yjsffNqdMOFiSMo4uH0eNg4ueh7WLYDXbvUenPHeA94tQQefGNHyRcQnL90MX66I7D77joav393q6qysLCZOnMhLL73EjBkzePLJJ/nWt76FmXHXXXeRlZVFbW0tJ598MsuXL2fMmDEt7ufDDz/kySefZOnSpdTU1DBhwgSOPvpoAM4++2wuu+wyAH72s5/x+9//nmuvvZbp06dz5plncu655zbZV0VFBbNmzWLBggUMGzaMiy66iIceeojrr78egF69erFkyRIefPBB7rnnHh577LE2/xj8ftRi924Zh0vOhPNmey3SgsXeAyc+fimyx6gshfd+53UnP3cFuDr45kPww2Vw3LUHH8T1zOCIU+CKhfDNh2FPoXcp1xPnwbbVbX9eRKQF4V3V4V3UTz31FBMmTGD8+PGsWrWqSZdyc2+//TZnnXUWKSkpZGRkMH369IZ1K1eu5IQTTmD06NE88cQTrT6Csd7HH3/M4MGDGTbM6z28+OKLWbhwYcP6s88+G4Cjjz664eESbfH7UYtqGYczgwkXwYCvwDOXwJzz4ZjL4LQ7ID754Pdbug0++D9Y9Jg3yGrg8XDm/3qXJwWi8HsoEIRxM+Gob8L7/wdv/y88PBnGXQBTfgo9+kf+mCISfftpwUbTjBkzuOGGG1iyZAllZWUcffTRfP7559xzzz0sWrSIzMxMZs2aRUVFxUHtf9asWcydO5exY8cye/Zs3nzzzUOqt/4xjJF4BGNHPWpRLeOW5AyD7y+AY6+BRY9653MPpmW54zOY/0O4d7QXiINP8vb7vRdg2NeiE8Th4pPh+Ovhh0vhKz+A5U95A8QW3K6R1yLSbmlpaUydOpVLLrmkoVVcUlJCamoqPXr0YNu2bbz00v57Ek888UTmzp1LeXk5paWlzJ8/v2FdaWkp/fr1o7q6mieeeKJheXp6OqWl+17pMnz4cDZs2MBnn30GwJ///GdOOumkQ/qOfj9qUS3j1sQleqOVh0z17m/96FTvvO4x3/da0PuzaRG8cy+sfQGCCV6L9LhrIfvwDil9H/UjrydeBv+8E97+H1j8BzjpJsi/BOIS/KlLRLqMmTNnctZZZzV0V48dO5bx48czYsQIBgwYwOTJk/f7+QkTJvDtb3+bsWPH0rt37yaPQbzjjjuYNGkSOTk5TJo0qSGAzz//fC677DLuv//+hoFbAElJSfzhD3/gvPPOo6amhmOOOYYrr7zygL5PZ3vUYmw/KCJS9myHuVfBZ6/D8NNh+gOQmt10m7o6+PRVeOc+2PguJPXwurgnXQFpvf2puzVbPoLXboHPF0LmIDj5VjjqrLZ/ZIhIh9ODIrouPSgi0tJ6e49k/NovvUB+eHLj/aFrquCjJ+ChY2HOt6F4E0y7G25YDSf/vPMFMcBh4+Gied5DNOJT4enveV3xG/7ld2UiIt2SuqnbKxCAY38AgybD05fCn2bA6PNgw9tQuhX6jPLudX3UWRCM97vatpnB0FPg8Kmw7El44y6YfQYMmwan3Aa99UtcRKSjqGV8oPqNhSve8kZdr3gKeg2F7zwDV/7Lu2tWVwjicIEgjL8Qrv3QC+Ev3vUu63r+GijZ4nd1IiLdglrGByMhFabfD6f/2hvoFQvik+H4G2D8Rd5TrT541LuL17FXe3cFO9RroEXkoDnnMI3p6FIOdDyWWsaHIlaCOFxqNkz7JVyzCEac4QXzfWO8u5Ot+2fXew60SBeXlJTEzp07D/gfd/GPc46dO3eSlJTU7s9oNLXs3+Yl3gjxT1+D6r2Q1NMbUT5yunfZV3z7/7KJyIGrrq6moKDgoG+oIf5ISkoiNzeX+Pimpy5bG02tMJb2qS73Wsar53m3Ca0shoQ0GHqaF8xHnOo9L1pERFrVWhjrnLG0T3yy12094gzvcq4NC71gXvsCrHoW4pLg8JO9YB72Ne9e3yIi0i5qGcuhqauFje95wbxmPpRugUCcd+vPkdNh+BmQluN3lSIinYK6qSX66upgyxJY/TysmQe7NoAFIO84L5hHnKmHVIhIt6Ywlo7lHGxbGWoxz4PC0AO+++d7wXzkNyBriL81ioh0MIWx+KvwEy+U18yHrUu9ZX1GNwZzzgjdG1tEYt5Bh7GZPQ6cCWx3zo1qYf0U4Hng89CiZ51zt7dVkMK4G9v1hRfKa+bDpvcBB9lDvVAeOR36jVMwi0hMOpQwPhHYA/xpP2H8Y+fcmQdSkMJYACj9MhTM82DDO+BqoUcejDgdeo/0urKzhkB6v+g//1lEJMoO+tIm59xCMxsUlapE0vt6z1meeBns3Qkfv+iF8+I/QG1l43ZxSZA52HsmdNbgxpDOGgIZ/b17bIuIdFGRus74WDNbBmzBayWvamkjM7scuBwgLy8vQoeWmJGaDRO+673qaqG4AIrWh70+h52feXcDCw/qYKL3XOaGgA6FdfbhkJELQV1OLyKdW7sGcIVaxv9opZs6A6hzzu0xs9OB+5xzQ9vap7qp5aDV1XnXM4cH9c51XlgXrYea8sZtA/GQObBpSzor1Lrumdf1nrIlIl1a1O7A5ZwrCZt+0cweNLNezrkdh7pvkRYFAtAj13sNPrHpOue889BNWtTrvPcv3oWqPY3bWtAL5PpWdM887xaf8SneHcca3pObLUvy3tU1LiIRcshhbGZ9gW3OOWdmE/GeBLXzkCsTORhmkNHPew2a3HSdc7C3sFlrOjRdsAgqS1reZ2uCCS0EdbJ3fru9gR6X6HXJuzqoq/Gm62q8V/NlrjZs/YEuq2vcL+bdrjQlG1KyQq9sSA691y+PxaeSiXRSbYaxmc0BpgC9zKwAuBWIB3DOPQycC1xlZjVAOXC+07O+pDMyg7Te3ivvK03XOeeFcVUZVJd5D8aoLg+bbvZeU9HCurDpPV9CdcW+nyVC/2tY0GuZB+K8lwVC08HGdwu2vAwHOz+FsqL9/wBJSPNCuXlI17+3tLw7BXhdnffAlPLdULEbKoqhptIb+d9zgPeEM12iJ+3UntHUM9tY/wDwQMQqEvGDGST18F7R4pz3j3V4eNdUNIZlQ6DGtb0sUv/I11RB+S4o2wnlRd572U4vqMuKmi4vWgdlu7wAak1CWiiks5qGdHJmY69AXFJYb0EyxCW3Ph/tUwE1VV6IVuwOhWr99K7GgK0P2ybri0M/ZPbz4yohDXoM8E6n9Ay998hrnE/vp1Md0kDDTEU6ilmoe7oTPQM6LgHS+3iv9qoP8H3CO/QevrxofagFvp8A359AfFi3fkvBndSs2z9sPhAHFSX7hmr4dHVZG38+yZDcM/RDrSdkHOZd/57UI7S8Z9P1wQRvcOHuTd7VAMWbvNfmD70/l3AW9C7Lawjq8OAOTSekHtyfm3Q5CmMROTAHE+B1tc2690PvLc6Xh/UclLeybbn3g2CfbcuhtqrpsRMzvKCsD9CsIY1B2hCmPVsO2Eh2u1ftbQzoJmFdAF+8ByVPe+f7wyVnhYVzC63s1F7t6yWpCxsz0Oqrdt/52uqW1weC3nX/mYM614/LLkxhLCLRFwhCYpr3irb64K+rhoT0znOdeUIq5Az3Xi2pq4XSrV44797U2KouLvAGG65/s+nVAOD1BKT2BlzTIK1tFrSRGquwD/N+JGSHLhnMPiJ0Y57DvUsKdelgu3WSv6UiIhFSH/xdTSDYeMle8wGG4I05qNgdFtYFULwR9hSGxhOEDegLxDebj2s6H2xpfVz791FbFbquf513I56d62Dl094pgHr1lw5mh0I66/DG0O6Zp/PlzSiMRUS6AgtdkpacCX1H+10N5Da7b4Vz3viAnZ+FQnpd4/sX70H13sZtA/GhO+UdHmpJD2lsVacf1i3vQ68wFhGRQ2fm3dI2NRvyJjVd5xzs2RYW0J81Xue//g1vPEC9uKTGu+WFt6p79G88b11b7bXOW5quqw4tq5+uCnXbN1++n+nwZd/+CySkRP2PT2EsIiLRZeY9FCa9774346mrg5LNYa3p0A15Cj+GT17xgjHyBXld9cGExm778OlAfGhZ/L6D6qJEYSwiIv4JBLwR4j0HwJApTdfV1niD2IrWQcnWsOCsD8wEb4DePtPxzUK1eeh2vvPVCmMREemcgnGhc8uD/a4k6rrfWXIREZFORmEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM/aDGMze9zMtpvZyja2O8bMaszs3MiVJyIiEvva0zKeDUzb3wZmFgR+BbwagZpERES6lTbD2Dm3EChqY7NrgWeA7ZEoSkREpDs55HPGZtYfOAt4qB3bXm5mi81scWFh4aEeWkREJCZEYgDXvcBNzrm6tjZ0zj3inMt3zuXn5ORE4NAiIiJdX1wE9pEPPGlmAL2A082sxjk3NwL7FhERiXmHHMbOucH102Y2G/iHglhERKT92gxjM5sDTAF6mVkBcCsQD+Cceziq1YmIiHQDbYaxc25me3fmnJt1SNWIiIh0Q7oDl4iIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuKzNsPYzB43s+1mtrKV9TPMbLmZLTWzxWZ2fOTLFBERiV3taRnPBqbtZ/0CYKxzbhxwCfDYoZclIiLSfbQZxs65hUDRftbvcc650Gwq4FrbVkRERPYVkXPGZnaWma0FXsBrHYuIiEg7RSSMnXPPOedGAN8E7mhtOzO7PHReeXFhYWEkDi0iItLlRXQ0dahLe4iZ9Wpl/SPOuXznXH5OTk4kDy0iItJlHXIYm9kRZmah6QlAIrDzUPcrIiLSXcS1tYGZzQGmAL3MrAC4FYgHcM49DJwDXGRm1UA58O2wAV0iIiLShjbD2Dk3s431vwJ+FbGKREREuhndgUtERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZ22GsZk9bmbbzWxlK+svNLPlZrbCzN41s7GRL1NERCR2tadlPBuYtp/1nwMnOedGA3cAj0SgLhERkW4jrq0NnHMLzWzQfta/Gzb7byA3AnWJiIh0G5E+Z3wp8FJrK83scjNbbGaLCwsLI3xoERGRriliYWxmU/HC+KbWtnHOPeKcy3fO5efk5ETq0CIiIl1am93U7WFmY4DHgK8753ZGYp8iIiLdxSG3jM0sD3gW+K5z7pNDL0lERKR7abNlbGZzgClALzMrAG4F4gGccw8DtwDZwINmBlDjnMuPVsEiIiKxpj2jqWe2sf77wPcjVpGIiEg3oztwiYiI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5rM4zN7HEz225mK1tZP8LM3jOzSjP7ceRLFBERiW3taRnPBqbtZ30RcB1wTyQKEhER6W7aDGPn3EK8wG1t/Xbn3CKgOpKFiYiIdBcdes7YzC43s8VmtriwsLAjDy0iItJpdWgYO+cecc7lO+fyc3JyOvLQIiIinZZGU4uIiPhMYSwiIuKzuLY2MLM5wBSgl5kVALcC8QDOuYfNrC+wGMgA6szsemCkc64kWkWLiIjEkjbD2Dk3s431XwK5EatIRESkm1E3tYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIzxTGIiIiPlMYi4iI+ExhLCIi4jOFsYiIiM8UxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+UxiLiIj4TGEsIiLiM4WxiIiIz2IijL/YuZern1hCcVm136WIiIgcsJgI45LyGl5e9SW3/2O136WIiIgcsJgI49G5PfjBlMN5ZkkBC9Zs87scERGRAxITYQxw7VeHMqJvOj95doW6q0VEpEuJmTBOiAtwz3ljKdpbxS/mr/K7HBERkXaLmTAGGNW/Bz+YegTPfrSZ11eru1pERLqGmApjgGumHsGR/TL4yXMr2F1W5Xc5IiIibWozjM3scTPbbmYrW1lvZna/mX1mZsvNbELky2w/r7t6DLv2VnHbPHVXi4hI59eelvFsYNp+1n8dGBp6XQ48dOhlHZqjDuvBNV89grlLt/Dqqi/9LkdERGS/2gxj59xCoGg/m8wA/uQ8/wZ6mlm/SBV4sK6eegQj+2Xw0+dWsmuvuqtFRKTzisQ54/7AprD5gtAyX8UHvdHVu8uquFXd1SIi0ol16AAuM7vczBab2eLCwsKoH2/kYRlcd/JQ5i3bwssr1V0tIiKdUyTCeDMwIGw+N7RsH865R5xz+c65/JycnAgcum1XTTmcUf0z+NncFRSpu1pERDqhSITxPOCi0KjqrwDFzrmtEdhvRNR3VxeXV6u7WkREOqX2XNo0B3gPGG5mBWZ2qZldaWZXhjZ5EVgPfAY8CvwgatUepBF9M/jhyUOZv2wLL63oNL8TREREAIhrawPn3Mw21jvg6ohVFCVXnnQ4r6zaxs/mrmTi4Cyy0xL9LklERASIwTtwtSYu1F1dWlHDLequFhGRTqTbhDHA8L7p/PCUobywfCsvLFd3tYiIdA7dKowBrjhxCGNye/Dz51eyY0+l3+WIiIh0vzCOCwb4n/PGsqeihlueb/F22yIiIh2q24UxwNA+6Vx/6lBeXPEl/1i+xe9yRESkm+uWYQxw+QlDGDugJz+fu5LCUnVXi4iIf7ptGHvd1WPYW1XLz+euxLtCS0REpON12zAGOKJ3Ov9x6jBeXvUl8zW6WkREfNKtwxjgshOGMG5AT255fiXbSyv8LkdERLqhbh/GwYBxz3ljKauq5WfPqbtaREQ6XrcPY4Ajeqfx49OG8erqbcxbptHVIiLSsRTGIZceP4QJeT25dd4qdVeLiEiHUhiHBAPGr88bS3lVLf9P3dUiItKBFMZhDs9J4z+/NpzXVm9j7tLNfpcjIiLdhMK4me9NHkz+wExum7ea7SXqrhYRkehTGDcTDBj/fe4YKqpr+elzK9RdLSIiUacwbsGQnDRunDaC19ds59kl6q4WEZHoUhi34nvHDeKYQZn8Yv4qtqm7WkREokhh3IpAwPj1uWOpqq3jJ8+qu1pERKJHYbwfg3qlctO0Efxz7XaeUXe1iIhEicK4DRcfO4iJg7P4xfxVfFms7moREYk8hXEbvO7qMdTUOm5+drm6q0VEJOIUxu0wMDuVm78+gjc/LuTvHxb4XY6IiMQYhXE7ffcrA/nKkCzumL+aLbvL/S5HRERiiMK4nQIB47/PGUutc9ys0dUiIhJBCuMDkJedws1fH8HCTwp5avEmv8sREZEYoTA+QN+ZNJBjh2Rz5z/WsFnd1SIiEgEK4wMUCN27utY5bn5mObV16q4WEZFD064wNrNpZvaxmX1mZje3sH6gmS0ws+Vm9qaZ5Ua+1M5jQFYKPz39SN7+dAfT7l3Iiyu2UqdQFhGRg9RmGJtZEPgd8HVgJDDTzEY22+we4E/OuTHA7cAvI11oZ3PhpDwevHACDvjBE0s447f/4rXV2zSwS0REDlh7WsYTgc+cc+udc1XAk8CMZtuMBP4Zmn6jhfUxx8w4fXQ/Xrn+RH7z7bGUV9Vw2Z8W883fvcObH29XKIuISLu1J4z7A+FDhwtCy8ItA84OTZ8FpJtZ9qGX1/kFA8ZZ43N5/T9O4r/PGcOOPVXM+sMiznv4Pd5dt8Pv8kREpAuI1ACuHwMnmdlHwEnAZqC2+UZmdrmZLTazxYWFhRE6dOcQFwzwrWMG8MaPp3DnN0dRsKucCx59n5mP/JvFG4r8Lk9ERDoxa6s71cyOBW5zzn0tNP8TAOdci+eFzSwNWOuc2+8grvz8fLd48eKDKrorqKiu5a/vb+TBN9exY08lJw3L4UenDWNMbk+/SxMREZ+Y2YfOufzmy9vTMl4EDDWzwWaWAJwPzGu2815mVr+vnwCPH2rBXV1SfJBLjh/MwhuncPPXR7C8YDfTH3iH7/9xMau3lPhdnoiIdCJthrFzrga4BngFWAM85ZxbZWa3m9n00GZTgI/N7BOgD3BXlOrtclIS4rjypMNZeONUfnTqMN7/fCen3/82Vz+xhE+3lfpdnoiIdAJtdlNHS6x3U7emuKyax/61nsf/9Tll1bV8c1x/fnjyUAb1SvW7NBERibLWuqkVxj4p2lvF/721jj++t4HqWsc5E/pz7VeHMiArxe/SREQkShTGndT20goefGMdf31/Iw7Ht48ZwDVTh9K3R5LfpYmISIQpjDu5rcXlPPDPz/jbok0EAsaFk/K4asrh9E5XKIuIxAqFcRexqaiM+xd8yrMfbSY+aFx83CCuOPFwslIT/C5NREQOkcK4i1lfuIf7FnzKvGVbSAldJvX9E4bQIzn+oPdZV+cor671XlW1VIRNN3lvtt4wpo3qy6j+PSL4DUVEuh+FcRf1ybZS7n39E15c8SUZSXF899iB9ExOoCwUnBXNQrSiutZbFx62oW0qa+oO+PjBgAFQW+cY3b8HF0zK4xtjDyMtMS7SX1VEJOYpjLu4VVuK+c1rn/L6mm0NyxKCAZLiAyQnBEmOD5KcEEdy2HxSvPeekhAkqX6b+CDJCd66lLBl4evDt48PBigur+b5pZv56/sbWftlKakJQaaP688FE/MYnavWsohIeymMY0RxeTXBgJEUFyAuGKlbi7ePc46PNu1mzvsbmb98CxXVdYzqn8EFEwcyfZxayyIibVEYS0SVVFTz/EebeSLUWk5JCDJj3GHMnJin+2+LiLRCYSxR4Zxj6abdzPlgI/OXbaW8upZR/TOYOTGP6WMPIz3p4AeciYjEGoWxRF1JRTXPL93CX9/fyJqtJaQkBJk+tr613AMz87tEERFfKYylwzjnWFZQzJz3NzJv2RbKq2sZ2S+DCyblMWOcWssi0n0pjMUXpWGt5dVbS0iOD7WWJ+UxVq1lEelmFMbiK+ccywuKmfOB11ouq6rlyH4ZXDBxADPG9ydDrWUR6QYUxtJplFZUM2+Z11petcVrLX9jbD9mTsxj3ICeai2LSMxSGEuntKKgmL9+sJF5Szezt6qWEX3TuXBSnlrLIhKTFMbSqe2prGHe0i3M+WAjKzYXExcweqcn0jsjiT4ZifROD71nJNEnI4ne6Yn0yUgiMyVeLWkR6TIUxtJlrCgo5pVVX7K1uILtpRVsL6lkW2kFu8uq99k2IRggJz2R3hmJ9AkL7Pqwrg/ungptEekEWgtj3b9QOp3RuT1avOd1RXUthaWVbC+tYFtJJdtKvPftJRVsL61kXeEe3l23g5KKmn0+mxAXaAjohvewFnefjCRy0hLJSI5veDiGiEhHURhLl5EUH2RAVgoDslL2u11FdW1Da7ohsOtb2CUVfLKtlH99toPSFkIbID0xjozkeNKTvPeMpHgykuNC7/FktLC8R2g+LSlOYS4iB0xhLDEnKT5IXnYKedn7D+2yqpqGgN5eWsn20kpKyqspqaimpLwm9F7N5t3lrNnqLW8twMMdSJiHP1zD4XAO6k8cOee8aeet85bR4jaNZ5ua76Nxv6FdETBITQzVkxRHepJXa0pCUF35Ij5RGEu3lZIQx6BecQzqldruz9TWOfZU1jQJ7dKKakoqaloM8pKKarbsLmftl958aWUNPg3TaFMwYKQnxXmvxPjQdOMPiYZ1oenGZY2hnhQfUKCLHASFscgBCAaMHslet/TBqKtz7KkKBXd5DXsqvZZ2fX5Zw7Q1W2bUR5wZWNj68GUN083nw45R56C0wvsR4b3XhFr9jfP1PzAKdpVRutWb31NZQ10bPyTig9YQ1vWhnpEcR8/kBHIzk8nLTmFgdioDs1I0qE4kjMJYpAMFAhbqHo6HTL+rOTDOOfZW1Xot/LAwL2n23jzUN+woo6hsN4WllU32l54Ux8DsFAZmpXohnZXSENb9MpII6Ny7dCMKYxFpFzMjLTGuyXnuA1FeVcvGojK+2LmXjUVloekyVm8t4dXVX1Jd29jsTggGyM1KZmCWF855WSlecGenkJuZQlJ8MFJfq92cc5RX11JSXkNx6BREcVl143R5NXsra6itgzrnwl7eZ2vrvOk6553D9+a96bqw9S70udqw6bo6qHUuNE/DfuvqHIGAkZOW0HBJX+/00HvoKoHs1ATigoEO//OSA6MwFpEOkZwQZHjfdIb3Td9nXW2dY8vu8oaA/qJoLxt3etOLNuxq6M4Hr7u9b0ZSWECHhXVWKj1SWj+FUFvn2FNR0yRAi8u98/kN0xXVFJfXNCwrCds2/AdDi98xPkhcwDuFEAgYQTPMjIBBwIxg/br6ZQFrnLbQdMCbNjOCYcvNIC4YaJiu3191bR0Fu8r5aONudu6t2qcmM8hOTQxd0hcK6wxvPifs2vyctEQS4hTaflEYi4jvggFruGxt8hFN1znnKNpbxRdFZQ0BXR/Wb3xcSGFpQZPteyTHMzA7hd7pieytrG0SvHvaGEAXDBgZSXEN4wIykuPpn5nccOla4/KwbULL05PifG+BVtfWsWNPZZPr77eXhk9XsGpLCTv2VLZ4/j8zJd675j69MbT7pCc2bXVnJPrSMxHrFMYi0qmZGdlpiWSnJTIhb98T7WVVNQ0t6o2hoP5iZxkFu8pJS4yjX48khvdNbwjX5mEbPp3axS/vig8G6NcjmX49kve7XW2dY+eeyoaA3l7iTYdf5rdu+w62l1ZS00JqpyfF0SstkazUBLJSE+iVlhCaTgybTqBXWiKZKQlqcbeDwlhEurSUhDhG9M1gRN8Mv0vpMoIB81q7GUnAvne7q1dX59hVVrVPC7uwtJKde6vYuaeSTUVlLN20m6K9VdS2Mty+tfDOTk0ku9l0dw3vdoWxmU0D7gOCwGPOububrc8D/gj0DG1zs3PuxciWKiIiHSkQaOyVOLLf/retq3OUVFSHQrqKor2VYdNV7NhTSdHeKjYVlfHRxt3sKms9vDOS4sgOhXd2agLZaV4re0BmCrlZyQzITKFfjyTfTwtEUpthbGZB4HfAqUABsMjM5jnnVodt9jPgKefcQ2Y2EngRGBSFekVEpBMKBIyeKQn0TEng8Jy2t68P7x2hsC7aW9kwvXOPF+RFe6v4YmcZSzbupmhv0/PccQGjX88kBmSmMCDTuywuNzPZG3uQmUKvtIQudcqhPS3jicBnzrn1AGb2JDADCA9jB9T3EfUAtkSySBERiS3h4d0e1bV1bN1dwaZdZWwqKgu9l7NpVxkL1m5jx56mI8mT44MN4ZyX1TSoB2Qlk97JnpfenjDuD2wKmy8AJjXb5jbgVTO7FkgFTmlpR2Z2OXA5QF5e3oHWKiIi3VR8MLDfe86XVdVQsKvcC+qiMjbt8i6V21RUxgefFzW5PA6gZ0q816LOauz69sI6mf6ZySTGdeyI8UgN4JoJzHbO/Y+ZHQv82cxGOefqwjdyzj0CPALe84wjdGwREenmUhLiGNYnnWF99r2O3TnH7rLqJq3p+qBevbWE11Zvo6q2Ma7MoE+6dy37/333aDJT29d6PxTtCePNwICw+dzQsnCXAtMAnHPvmVkS0AvYHokiRUREDpaZkZmaQGZqAmNye+6zvq7Osa20wgvq0N3hNu0qY/OuctKTOuaio/YcZREw1MwG44Xw+cAFzbbZCJwMzDazI4EkoDCShYqIiERDIGAN12dPHJzlTw1tbeCcqwGuAV4B1uCNml5lZreb2fTQZj8CLjOzZcAcYJZznfVBcSIiIp1Lu9rfoWuGX2y27Jaw6dXA5MiWJiIi0j3EzhXTIiIiXZTCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERn5lfz3Mws0LgiwjushewI4L766z0PWOLvmds0feMLdH4ngOdcznNF/oWxpFmZoudc/l+1xFt+p6xRd8ztuh7xpaO/J7qphYREfGZwlhERMRnsRTGj/hdQAfR94wt+p6xRd8ztnTY94yZc8YiIiJdVSy1jEVERLqkmAhjM5tmZh+b2WdmdrPf9USDmQ0wszfMbLWZrTKzH/pdUzSZWdDMPjKzf/hdS7SYWU8ze9rM1prZGjM71u+aosHMbgj9nV1pZnPMLMnvmiLBzB43s+1mtjJsWZaZvWZmn4beM/2sMRJa+Z6/Dv29XW5mz5lZTx9LjIiWvmfYuh+ZmTOzXtE6fpcPYzMLAr8Dvg6MBGaa2Uh/q4qKGuBHzrmRwFeAq2P0e9b7IbDG7yKi7D7gZefcCGAsMfh9zaw/cB2Q75wbBQSB8/2tKmJmA9OaLbsZWOCcGwosCM13dbPZ93u+Boxyzo0BPgF+0tFFRcFs9v2emNkA4DRgYzQP3uXDGJgIfOacW++cqwKeBGb4XFPEOee2OueWhKZL8f7h7u9vVdFhZrnAGcBjftcSLWbWAzgR+D2Ac67KObfb16KiJw5INrM4IAXY4nM9EeGcWwgUNVs8A/hjaPqPwDc7sqZoaOl7Oudedc7VhGb/DeR2eGER1sp/T4DfADcCUR1gFQth3B/YFDZfQIyGVD0zGwSMB973uZRouRfvL3+dz3VE02CgEPhDqDv+MTNL9buoSHPObQbuwWtVbAWKnXOv+ltVVPVxzm0NTX8J9PGzmA5yCfCS30VEg5nNADY755ZF+1ixEMbdipmlAc8A1zvnSvyuJ9LM7Exgu3PuQ79ribI4YALwkHNuPLCX2OjSbCJ0znQG3o+Pw4BUM/uOv1V1DOddqhLTl6uY2f/DO4X2hN+1RJqZpQA/BW7piOPFQhhvBgaEzeeGlsUcM4vHC+InnHPP+l1PlEwGppvZBrxTDl81s7/4W1JUFAAFzrn63o2n8cI51pwCfO6cK3TOVQPPAsf5XFM0bTOzfgCh9+0+1xM1ZjYLOBO40MXmNbKH4/2IXBb69ygXWGJmfaNxsFgI40XAUDMbbGYJeIND5vlcU8SZmeGdX1zjnPtfv+uJFufcT5xzuc65QXj/Lf/pnIu5lpRz7ktgk5kNDy06GVjtY0nRshH4ipmlhP4On0wMDlQLMw+4ODR9MfC8j7VEjZlNwzuVNN05V+Z3PdHgnFvhnOvtnBsU+veoAJgQ+n834rp8GIcGEVwDvIL3P/lTzrlV/lYVFZOB7+K1FJeGXqf7XZQckmuBJ8xsOTAO+C9/y4m8UMv/aWAJsALv35yYuHuTmc0B3gOGm1mBmV0K3A2camaf4vUK3O1njZHQyvd8AEgHXgv9W/Swr0VGQCvfs+OOH5u9CyIiIl1Hl28Zi4iIdHUKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHx2f8HBOtgng2YEDkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I slept.\n",
      "Decoded sentence: அவன் க் க்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/jayanti/opt/anaconda3/envs/transformers_env/lib/python3.9/site-packages\")\n",
    "#Importing library\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import time, random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,  TensorBoard\n",
    "   \n",
    "\n",
    "def get_data (num_samples):\n",
    "\n",
    "    #with open('/Users/jayanti/Data/Seq2Seq/fra.txt', 'r', encoding='utf-8') as f:\n",
    "    #    lines = f.read().split('\\n')\n",
    "    \n",
    "    \n",
    "    with open('/Users/jayanti/Data/Seq2Seq/tam.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    \n",
    "    input_chars = set()\n",
    "    target_chars = set()\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    \n",
    "    \n",
    "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "        input_text, target_text, extra = line.split('\\t')\n",
    "        target_text = '\\t' + target_text + '\\n'\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        \n",
    "        for char in input_text:\n",
    "            if char not in input_chars:\n",
    "                input_chars.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_chars:\n",
    "                target_chars.add(char)\n",
    "\n",
    "            \n",
    "    input_chars = sorted(list(input_chars))\n",
    "    target_chars = sorted(list(target_chars))\n",
    "    \n",
    "\n",
    "    num_encoder_tokens = len(input_chars)\n",
    "    num_decoder_tokens = len(target_chars)\n",
    "    max_encoder_seq_len = max([len(txt) for txt in input_texts])\n",
    "    max_decoder_seq_len = max([len(txt) for txt in target_texts])\n",
    "\n",
    "    P = {'num_encoder_tokens': num_encoder_tokens, \n",
    "        'num_decoder_tokens': num_decoder_tokens,\n",
    "        'max_encoder_seq_len': max_encoder_seq_len,\n",
    "        'max_decoder_seq_len': max_decoder_seq_len,\n",
    "        'input_chars': input_chars,\n",
    "        'target_chars': target_chars}\n",
    " \n",
    "\n",
    "    #Define data for encoder and decoder\n",
    "    input_token_id = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "    target_token_id = dict([(char, i) for i, char in enumerate(target_chars)])\n",
    "\n",
    "    return P, input_token_id, target_token_id, input_texts, target_texts  \n",
    "\n",
    "\n",
    "def data_vectorize (P, input_texts, target_texst, input_token_id, target_token_id):\n",
    "    \n",
    "    num_encoder_tokens = P['num_encoder_tokens']\n",
    "    num_decoder_tokens = P['num_decoder_tokens']\n",
    "    \n",
    "    max_encoder_seq_len = P['max_encoder_seq_len']\n",
    "    max_decoder_seq_len = P['max_decoder_seq_len']\n",
    "    input_chars = P['input_chars']\n",
    "    target_chars = P['target_chars']\n",
    " \n",
    "    encoder_in_data = np.zeros((len(input_texts), max_encoder_seq_len, num_encoder_tokens), dtype='float32')\n",
    "    decoder_in_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_in_data[i, t, input_token_id[char]] = 1.\n",
    "   \n",
    "        for t, char in enumerate(target_text):\n",
    "             decoder_in_data[i, t, target_token_id[char]] = 1.\n",
    "             if t > 0:\n",
    "                decoder_target_data[i, t - 1, target_token_id[char]] = 1.\n",
    "\n",
    "    return encoder_in_data, decoder_in_data,  decoder_target_data\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq_Model:\n",
    "    def __init__(self, workspace, num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
    "        \n",
    "        self.workspace = workspace \n",
    "        self.model_dir = self.workspace + os.sep + \"trained_model\"\n",
    "        self.log_dir = self.workspace + os.sep + \"log\"\n",
    "        \n",
    "        os.makedirs (self.workspace, exist_ok=True)\n",
    "        os.makedirs (self.model_dir, exist_ok=True)\n",
    "        os.makedirs (self.log_dir, exist_ok=True)\n",
    "        \n",
    "        #Define and process the input sequence\n",
    "        encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "        encoder = LSTM(latent_dim, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "        #We discard `encoder_outputs` and only keep the states.\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        #Using `encoder_states` set up the decoder as initial state.\n",
    "        decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        #Final model\n",
    "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        #Model Summary\n",
    "        print(self.model.summary())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Define sampling models\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "        decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "        decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit_model (self, encoder_in_data, decoder_in_data,  decoder_target_data, nepochs):\n",
    "        batch_size = 64\n",
    "        \n",
    "         \n",
    "        \n",
    "        chkpt = ModelCheckpoint(filepath = self.model_dir + os.sep +\"model.hdf5\", \n",
    "                                save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "        \n",
    "        tboard = TensorBoard(log_dir=self.log_dir)\n",
    "        \n",
    "        callbacks = [chkpt, tboard]    \n",
    "            \n",
    "            \n",
    "            \n",
    "        #Compiling and training the model\n",
    "        self.model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), \n",
    "            loss='categorical_crossentropy')\n",
    "        \n",
    "        hist = self.model.fit([encoder_in_data, decoder_in_data],\n",
    "            decoder_target_data, callbacks=callbacks, batch_size = batch_size, epochs=nepochs, validation_split=0.2)\n",
    "\n",
    "        return hist \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def decode_sequence(P, M, input_token_id, target_token_id, input_seq):\n",
    "    \n",
    "    num_encoder_tokens = P['num_encoder_tokens']\n",
    "    num_decoder_tokens = P['num_decoder_tokens']\n",
    "    \n",
    "    max_encoder_seq_len = P['max_encoder_seq_len']\n",
    "    max_decoder_seq_len = P['max_decoder_seq_len']\n",
    "    \n",
    "    reverse_input_char_index = dict((i, char) for char, i in input_token_id.items())\n",
    "    reverse_target_char_index = dict((i, char) for char, i in target_token_id.items())\n",
    "\n",
    "    \n",
    "    #Encode the input as state vectors.\n",
    "    states_value = M.encoder_model.predict(input_seq)\n",
    "\n",
    "    #Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "\n",
    "    #Get the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_id['\\t']] = 1.\n",
    "\n",
    "\n",
    "    #Sampling loop for a batch of sequences\n",
    "    #(to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = M.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        #Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        #Exit condition: either hit max length\n",
    "        #or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "            len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "    \n",
    "        #Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        #Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #Hyperparameters\n",
    "    batch_size = 64\n",
    "    latent_dim = 256\n",
    "    num_samples = 20000\n",
    "\n",
    "\n",
    "    \n",
    "    P, input_token_id, target_token_id, input_texts, target_texts = get_data (num_samples)\n",
    "    \n",
    "    print(P['input_chars'])\n",
    "    print(P['target_chars'])\n",
    "    #sys.exit()\n",
    "    \n",
    "    encoder_in_data, decoder_in_data,  decoder_target_data = data_vectorize (P, input_texts, target_texts, input_token_id, target_token_id)\n",
    "        \n",
    "        \n",
    "\n",
    "    M =  Seq2Seq_Model (\"tmp_results_hn\",P['num_encoder_tokens'], P['num_decoder_tokens'], latent_dim)  \n",
    "\n",
    "    #Model Summary\n",
    "    print(M.model.summary())\n",
    "    \n",
    "    print(\"encoder_in_data shape:\",encoder_in_data.shape)\n",
    "    print(\"decoder_in_data shape:\",decoder_in_data.shape)\n",
    "    print(\"decoder_target_data shape:\",decoder_target_data.shape)\n",
    "\n",
    "    #Visuaize the model\n",
    "    plot_model(M.model,show_shapes=True)\n",
    "    plt.show()\n",
    "    \n",
    "    hist = M.fit_model (encoder_in_data, decoder_in_data,  decoder_target_data,15)\n",
    "\n",
    "    fig, axs = plt.subplots (1,1,figsize=(8,6))\n",
    "    axs.plot(hist.history['loss'],label='Training Loss')\n",
    "    axs.plot(hist.history['val_loss'],label='Validation Loss')\n",
    "    axs.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    for seq_index in range(10):\n",
    "        input_seq = encoder_in_data[seq_index: seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(P, M, input_token_id, target_token_id,input_seq)\n",
    "        print('-')\n",
    "        print('Input sentence:', input_texts[seq_index])\n",
    "        print('Decoded sentence:', decoded_sentence)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e7d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
