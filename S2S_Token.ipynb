{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f30ff4-e97c-4ae4-8f75-6be2d656204b",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://cnvrg.io/seq2seq-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a9a293-39ec-4231-bc78-c62770389b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source tokens {'19.': 0, 'Ask': 1, 'Attack!': 2, 'Awesome!': 3, 'Be': 4, 'Beat': 5, 'Call': 6, 'Cheers!': 7, 'Come': 8, 'Drop': 9, 'Fire!': 10, 'Get': 11, 'Go': 12, 'Go.': 13, 'Got': 14, 'Help!': 15, 'Hop': 16, 'Hug': 17, 'I': 18, \"I'm\": 19, 'Jump.': 20, 'Listen.': 21, 'No': 22, 'OK.': 23, 'Oh': 24, 'Really?': 25, 'Run!': 26, 'Stop!': 27, 'Thanks.': 28, 'Tom.': 29, 'Wait!': 30, 'We': 31, 'Wow!': 32, 'calm.': 33, 'cool.': 34, 'fair.': 35, 'fell.': 36, 'in.': 37, 'it!': 38, 'it.': 39, 'it?': 40, 'kind.': 41, 'know.': 42, 'left.': 43, 'lost.': 44, 'me.': 45, 'nice.': 46, 'no!': 47, 'now.': 48, 'on!': 49, 'on.': 50, 'see.': 51, 'try.': 52, 'up.': 53, 'us.': 54, 'way!': 55, 'won!': 56, 'won.': 57}\n",
      "target tokens: {'!': 0, '19': 1, '?': 2, 'Ah': 3, 'Allez': 4, 'Allez-y': 5, 'Appelez-nous': 6, 'Appelle-moi': 7, 'Appelle-nous': 8, 'Appellez-moi': 9, 'Arrête-toi': 10, 'Attaque': 11, 'Attaquez': 12, 'Attendez': 13, 'Attends': 14, 'Au': 15, \"C'est\": 16, 'Compris': 17, 'Continuez.': 18, 'Courez': 19, 'Cours': 20, 'Demande': 21, 'Dégage': 22, 'En': 23, 'Entre': 24, 'Entre.': 25, 'Entrez': 26, 'Fantastique': 27, 'Hors': 28, 'Il': 29, 'Impossible': 30, \"J'ai\": 31, \"J'essaye.\": 32, 'Je': 33, 'Laisse': 34, 'Lève-toi.': 35, 'Merci': 36, 'Monte.': 37, 'Montez.': 38, 'Nous': 39, 'Oh': 40, 'On': 41, 'Pigé': 42, 'Poursuis.': 43, 'Poursuivez.': 44, 'Sans': 45, 'Santé': 46, 'Saute.': 47, 'Serre-moi': 48, 'Serrez-moi': 49, 'Sois': 50, 'Soyez': 51, 'Stop': 52, \"T'as\": 53, 'Tchin-tchin': 54, 'Tom.': 55, 'Va': 56, 'Va,': 57, 'Vas-y': 58, 'Venez': 59, 'Viens': 60, 'Vrai': 61, 'Vraiment': 62, 'alors': 63, 'ans.': 64, 'aucun': 65, 'aucune': 66, 'avons': 67, 'bien.': 68, 'bon': 69, 'bras': 70, 'calme': 71, 'calmes': 72, 'capté': 73, 'cas.': 74, 'comprends.': 75, 'dans': 76, 'de': 77, 'détendu': 78, 'emporté': 79, 'emporté.': 80, 'essaye.': 81, 'est': 82, 'exclu': 83, 'façons': 84, 'feu': 85, 'gagnâmes.': 86, 'gagné': 87, 'gagné.': 88, 'gentil': 89, 'gentil.': 90, 'gentille': 91, 'gentilles': 92, 'gentils': 93, 'hors': 94, 'juste': 95, 'justes': 96, \"l'ai\": 97, \"l'aide\": 98, \"l'avons\": 99, \"l'emportâmes.\": 100, 'maintenant.': 101, 'manière': 102, \"n'en\": 103, 'non': 104, 'parti.': 105, 'partie.': 106, 'pas': 107, 'perdu.': 108, 'pigé': 109, 'possible': 110, 'question': 111, 'sais.': 112, 'santé': 113, 'suffit': 114, 'suis': 115, 'tes': 116, 'tomber': 117, 'tombé.': 118, 'tombée.': 119, 'va.': 120, 'vais': 121, 'vos': 122, 'votre': 123, 'À': 124, 'Ça': 125, 'Écoutez': 126, 'à': 127, 'équitable': 128, 'équitables': 129}\n",
      "58 130 {'19.': 0, 'Ask': 1, 'Attack!': 2, 'Awesome!': 3, 'Be': 4, 'Beat': 5, 'Call': 6, 'Cheers!': 7, 'Come': 8, 'Drop': 9, 'Fire!': 10, 'Get': 11, 'Go': 12, 'Go.': 13, 'Got': 14, 'Help!': 15, 'Hop': 16, 'Hug': 17, 'I': 18, \"I'm\": 19, 'Jump.': 20, 'Listen.': 21, 'No': 22, 'OK.': 23, 'Oh': 24, 'Really?': 25, 'Run!': 26, 'Stop!': 27, 'Thanks.': 28, 'Tom.': 29, 'Wait!': 30, 'We': 31, 'Wow!': 32, 'calm.': 33, 'cool.': 34, 'fair.': 35, 'fell.': 36, 'in.': 37, 'it!': 38, 'it.': 39, 'it?': 40, 'kind.': 41, 'know.': 42, 'left.': 43, 'lost.': 44, 'me.': 45, 'nice.': 46, 'no!': 47, 'now.': 48, 'on!': 49, 'on.': 50, 'see.': 51, 'try.': 52, 'up.': 53, 'us.': 54, 'way!': 55, 'won!': 56, 'won.': 57} {'!': 0, '19': 1, '?': 2, 'Ah': 3, 'Allez': 4, 'Allez-y': 5, 'Appelez-nous': 6, 'Appelle-moi': 7, 'Appelle-nous': 8, 'Appellez-moi': 9, 'Arrête-toi': 10, 'Attaque': 11, 'Attaquez': 12, 'Attendez': 13, 'Attends': 14, 'Au': 15, \"C'est\": 16, 'Compris': 17, 'Continuez.': 18, 'Courez': 19, 'Cours': 20, 'Demande': 21, 'Dégage': 22, 'En': 23, 'Entre': 24, 'Entre.': 25, 'Entrez': 26, 'Fantastique': 27, 'Hors': 28, 'Il': 29, 'Impossible': 30, \"J'ai\": 31, \"J'essaye.\": 32, 'Je': 33, 'Laisse': 34, 'Lève-toi.': 35, 'Merci': 36, 'Monte.': 37, 'Montez.': 38, 'Nous': 39, 'Oh': 40, 'On': 41, 'Pigé': 42, 'Poursuis.': 43, 'Poursuivez.': 44, 'Sans': 45, 'Santé': 46, 'Saute.': 47, 'Serre-moi': 48, 'Serrez-moi': 49, 'Sois': 50, 'Soyez': 51, 'Stop': 52, \"T'as\": 53, 'Tchin-tchin': 54, 'Tom.': 55, 'Va': 56, 'Va,': 57, 'Vas-y': 58, 'Venez': 59, 'Viens': 60, 'Vrai': 61, 'Vraiment': 62, 'alors': 63, 'ans.': 64, 'aucun': 65, 'aucune': 66, 'avons': 67, 'bien.': 68, 'bon': 69, 'bras': 70, 'calme': 71, 'calmes': 72, 'capté': 73, 'cas.': 74, 'comprends.': 75, 'dans': 76, 'de': 77, 'détendu': 78, 'emporté': 79, 'emporté.': 80, 'essaye.': 81, 'est': 82, 'exclu': 83, 'façons': 84, 'feu': 85, 'gagnâmes.': 86, 'gagné': 87, 'gagné.': 88, 'gentil': 89, 'gentil.': 90, 'gentille': 91, 'gentilles': 92, 'gentils': 93, 'hors': 94, 'juste': 95, 'justes': 96, \"l'ai\": 97, \"l'aide\": 98, \"l'avons\": 99, \"l'emportâmes.\": 100, 'maintenant.': 101, 'manière': 102, \"n'en\": 103, 'non': 104, 'parti.': 105, 'partie.': 106, 'pas': 107, 'perdu.': 108, 'pigé': 109, 'possible': 110, 'question': 111, 'sais.': 112, 'santé': 113, 'suffit': 114, 'suis': 115, 'tes': 116, 'tomber': 117, 'tombé.': 118, 'tombée.': 119, 'va.': 120, 'vais': 121, 'vos': 122, 'votre': 123, 'À': 124, 'Ça': 125, 'Écoutez': 126, 'à': 127, 'équitable': 128, 'équitables': 129}\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_58 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_28 (Embedding)    (None, None, 50)             2850      ['input_57[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_29 (Embedding)    (None, None, 50)             6450      ['input_58[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_28 (LSTM)              [(None, 50),                 20200     ['embedding_28[0][0]']        \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_29 (LSTM)              [(None, None, 50),           20200     ['embedding_29[0][0]',        \n",
      "                              (None, 50),                            'lstm_28[0][1]',             \n",
      "                              (None, 50)]                            'lstm_28[0][2]']             \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, None, 130)            6630      ['lstm_29[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56330 (220.04 KB)\n",
      "Trainable params: 56330 (220.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B84C8FF3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B84036F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "decoded \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "decoded  cas.\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "decoded  cas. cas.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "decoded  cas. cas. tes\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "decoded  cas. cas. tes tes\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "decoded  cas. cas. tes tes tes\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "decoded  cas. cas. tes tes tes tes\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes Fantastique\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "decoded \n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "decoded  cas.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "decoded  cas. cas. tes\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "decoded  cas. cas. tes tes\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas. tes tes tes\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "decoded  cas. cas. tes tes tes tes\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes Fantastique\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "decoded \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "decoded  cas.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "decoded  cas. cas.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "decoded  cas. cas. tes\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "decoded  cas. cas. tes tes\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas. tes tes tes\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "decoded  cas. cas. tes tes tes tes\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes Fantastique\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "decoded \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas. tes\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas. tes tes\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "decoded  cas. cas. tes tes tes\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "decoded  cas. cas. tes tes tes tes\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "decoded  cas. cas. tes tes tes tes tes tes tes Fantastique\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "embedding_size = 50\n",
    "\n",
    "def get_data ():\n",
    "    lines= pd.read_table('fra.txt', names=['eng','fr'])\n",
    "    lines = lines[:100]\n",
    "    return lines \n",
    "\n",
    "\n",
    "\n",
    "def preprocess(lines):\n",
    "    lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "    lines.fr=lines.fr.apply(lambda x: x.lower())\n",
    "    lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "    lines.fr=lines.fr.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "    exclude = set(string.punctuation)\n",
    "    lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "    lines.fr=lines.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "    lines.fr=lines.fr.apply(lambda x: x.translate(remove_digits))\n",
    "    lines.fr = lines.fr.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "    return lines \n",
    "\n",
    "\n",
    "class Seq2Seq_Model:\n",
    "    def __init__(self, num_encoder_tokens, num_decoder_tokens):\n",
    "        self.num_encoder_tokens = num_encoder_tokens\n",
    "        self.num_decoder_tokens = num_decoder_tokens\n",
    "        self.model = None\n",
    "        self.encoder_model = None \n",
    "        self.decoder_model = None\n",
    "        self.get_models ()\n",
    "        \n",
    "    def get_models (self):\n",
    "        \n",
    "        encoder_inputs = Input(shape=(None,))\n",
    "        en_x =  Embedding(self.num_encoder_tokens-1, embedding_size)(encoder_inputs)\n",
    "        encoder = LSTM(50, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "\n",
    "        # We discard `encoder_outputs` and only keep the states.\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None,))\n",
    "        dex =  Embedding(num_decoder_tokens-1, embedding_size)\n",
    "        final_dex= dex(decoder_inputs)\n",
    "\n",
    "        decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(final_dex, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "        decoder_state_input_h = Input(shape=(50,))\n",
    "        decoder_state_input_c = Input(shape=(50,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        final_dex2 = dex(decoder_inputs)\n",
    "        decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "        decoder_states2 = [state_h2, state_c2]\n",
    "        decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs2] + decoder_states2)\n",
    "    \n",
    "    def fit_model (self, encoder_input_data, decoder_input_data, decoder_target_data):\n",
    " \n",
    "        self.model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        hist = self.model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=128, epochs=10,\n",
    "         validation_split=0.05)\n",
    "   \n",
    "        return hist \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq, M, input_token_index, target_token_index):\n",
    "    target_token_index['START_'] = 1\n",
    "    \n",
    "    reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "    reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "    encoder_model =  M.encoder_model \n",
    "    decoder_model =  M.decoder_model \n",
    "     \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) \n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        print(\"decoded\", decoded_sentence)\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 52):\n",
    "             stop_condition = True\n",
    "    \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "def preproc (lines):\n",
    "    all_eng_words=set()\n",
    "    for eng in lines.eng:\n",
    "        for word in eng.split():\n",
    "            if word not in all_eng_words:\n",
    "                all_eng_words.add(word)\n",
    "\n",
    "    all_french_words=set()\n",
    "    for fr in lines.fr:\n",
    "        for word in fr.split():\n",
    "            if word not in all_french_words:\n",
    "                all_french_words.add(word)\n",
    "\n",
    "    input_words = sorted(list(all_eng_words))\n",
    "    target_words = sorted(list(all_french_words))\n",
    "    num_encoder_tokens = len(all_eng_words)\n",
    "    num_decoder_tokens = len(all_french_words)\n",
    "\n",
    "    input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
    "    target_token_index = dict([(word, i) for i, word in enumerate(target_words)])\n",
    "    return num_encoder_tokens, num_decoder_tokens, input_token_index, target_token_index \n",
    "\n",
    "\n",
    "def tokenization (lines, eng_dict, fr_dict):\n",
    "   \n",
    "    encoder_input_data = np.zeros((len(lines.eng), 7),dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(lines.fr), 16),dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(lines.fr), 16, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "    eng = lines.eng\n",
    "    fr = lines.fr\n",
    "    encoder_input_data= []\n",
    "    decoder_input_data = []\n",
    "\n",
    "    for i in range (0, len (eng)):\n",
    "        src = eng[i].split(\" \")\n",
    "        tgt =  fr[i].split(\" \")\n",
    "        #tgt = ['START_']  + tgt + ['END_'] \n",
    "        src = [ eng_dict[k] for k in src if k in eng_dict]  \n",
    "        tgt = [ fr_dict[k] for k in tgt if k in fr_dict] \n",
    "        #src = [eng_dict['PAD_']] * ( 7- len (src)) + src \n",
    "        #tgt = [fr_dict['PAD_']] * (16 - len(tgt)) + tgt \n",
    "        encoder_input_data.append (src)\n",
    "        decoder_input_data.append (tgt)\n",
    "        \n",
    "    return encoder_input_data, decoder_input_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_encoder_tokens = 1000\n",
    "    num_decoder_tokens = 2000\n",
    "    \n",
    "    lines = get_data () \n",
    "\n",
    "    #lines  = preprocess(lines)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"lines\",lines)\n",
    "    \n",
    "    num_encoder_tokens, num_decoder_tokens, input_token_index, target_token_index = preproc (lines)\n",
    "\n",
    "\n",
    "    #target_token_index['START_'] = len (target_token_index.keys()) \n",
    "    #target_token_index['END_'] = len (target_token_index.keys()) \n",
    "    #target_token_index['PAD_'] = len (target_token_index.keys()) \n",
    "\n",
    "    #input_token_index['PAD_'] = len (input_token_index.keys()) \n",
    "    \n",
    "    print(\"source tokens\", input_token_index)\n",
    "    print(\"target tokens:\", target_token_index)\n",
    "    #sys.exit()\n",
    "    \n",
    "    print(num_encoder_tokens, num_decoder_tokens, input_token_index, target_token_index )\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(lines.eng), 7),dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(lines.fr), 16),dtype='float32')\n",
    "    ecoder_target_data = np.zeros((len(lines.fr), 16, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "    #print(encoder_input_data)\n",
    "    #encoder_input_data, decoder_input_data  = tokenization (lines, input_token_index, target_token_index )\n",
    "    #decoder_input_data = np.zeros((len(lines.fr), 16),dtype='float32')\n",
    "    #sys.exit()\n",
    "    \n",
    "    M = Seq2Seq_Model (num_encoder_tokens, num_decoder_tokens)\n",
    "\n",
    "    print(M.model.summary())\n",
    "    \n",
    "    hist = M.fit_model (encoder_input_data, decoder_input_data, decoder_target_data)\n",
    "\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.show()\n",
    "    print(hist.history)\n",
    "    \n",
    "    for seq_index in [91,2,45,40]:\n",
    "       input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "       decoded_sentence = decode_sequence(input_seq, M, input_token_index, target_token_index)\n",
    "    #    print('-')\n",
    "    #    print('Input sentence:', lines.eng[seq_index: seq_index + 1])\n",
    "    #    print('Decoded sentence:', decoded_sentence)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c55a2-dcad-495e-af41-91f53c1faac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b20157-0abf-46d6-b8ae-d26e49474198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
