{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a325a65-0049-4e33-841a-87b15a5f0885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Seq2Seq-Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Decoder-Input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " Decoder-Embedding (Embeddi  (None, None, 30)             60000     ['Decoder-Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " Encoder-Input (InputLayer)  [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " Decoder-Batchnorm-1 (Batch  (None, None, 30)             120       ['Decoder-Embedding[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Encoder-Model (Functional)  (None, 30)                   35700     ['Encoder-Input[0][0]']       \n",
      "                                                                                                  \n",
      " Decoder-GRU (GRU)           [(None, None, 30),           5580      ['Decoder-Batchnorm-1[0][0]', \n",
      "                              (None, 30)]                            'Encoder-Model[0][0]']       \n",
      "                                                                                                  \n",
      " Decoder-Batchnorm-2 (Batch  (None, None, 30)             120       ['Decoder-GRU[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Final-Output-Dense (Dense)  (None, None, 2000)           62000     ['Decoder-Batchnorm-2[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 163520 (638.75 KB)\n",
      "Trainable params: 163340 (638.05 KB)\n",
      "Non-trainable params: 180 (720.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"Encoder-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder-Input (InputLayer)  [(None, 10)]              0         \n",
      "                                                                 \n",
      " Encoder-Embedding (Embeddi  (None, 10, 30)            30000     \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " Encoder-Batchnorm-1 (Batch  (None, 10, 30)            120       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Encoder-Last-GRU (GRU)      [(None, 30),              5580      \n",
      "                              (None, 30)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35700 (139.45 KB)\n",
      "Trainable params: 35640 (139.22 KB)\n",
      "Non-trainable params: 60 (240.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Decoder-Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Decoder-Input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " Decoder-Embedding (Embeddi  (None, None, 30)             60000     ['Decoder-Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " Decoder-Batchnorm-1 (Batch  (None, None, 30)             120       ['Decoder-Embedding[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " hidden_state_input (InputL  [(None, 30)]                 0         []                            \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Decoder-GRU (GRU)           [(None, None, 30),           5580      ['Decoder-Batchnorm-1[0][0]', \n",
      "                              (None, 30)]                            'hidden_state_input[0][0]']  \n",
      "                                                                                                  \n",
      " Decoder-Batchnorm-2 (Batch  (None, None, 30)             120       ['Decoder-GRU[1][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Final-Output-Dense (Dense)  (None, None, 2000)           62000     ['Decoder-Batchnorm-2[1][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 127820 (499.30 KB)\n",
      "Trainable params: 127700 (498.83 KB)\n",
      "Non-trainable params: 120 (480.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import rmtree\n",
    "import tensorflow  as tf\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Embedding, BatchNormalization, GRU\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "num_encoder_tokens  = 1000\n",
    "num_decoder_tokens  = 2000\n",
    "input_vec_len = 10\n",
    "output_vec_len = 20\n",
    "\n",
    "def build_model (num_input_tokens, num_output_tokens, input_seq_len,output_seq_len, latent_dim) :\n",
    "     enc_inp = Input(shape = (input_seq_len,), name = \"Encoder-Input\")\n",
    "     embd = Embedding(num_input_tokens, latent_dim, name='Encoder-Embedding', mask_zero=False)\n",
    "     embd_outp = embd(enc_inp)\n",
    "\n",
    "     x = BatchNormalization(name='Encoder-Batchnorm-1')(embd_outp)\n",
    "     _, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n",
    "\n",
    "     enc_model = Model(inputs = enc_inp, outputs=state_h, name='Encoder-Model')\n",
    "     enc_outp = enc_model(enc_inp)\n",
    "\n",
    "     # get the decoder \n",
    "     dec_inp = Input(shape=(None,), name='Decoder-Input')\n",
    "     dec_emb = Embedding(num_output_tokens, latent_dim, name='Decoder-Embedding', mask_zero=False)(dec_inp)\n",
    "        \n",
    "     dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "     decoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
    "     decoder_gru_output, _ = decoder_gru(dec_bn, initial_state= enc_outp)\n",
    "\n",
    "     x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
    "     dec_dense = Dense(num_output_tokens, activation='softmax', name='Final-Output-Dense')\n",
    "     dec_outp = dec_dense(x)\n",
    "\n",
    "     model_inp = [enc_inp, dec_inp]\n",
    "     model = Model(model_inp, dec_outp,name=\"Seq2Seq-Model\")\n",
    "\n",
    "     gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n",
    "     gru_out, gru_state_out = decoder_gru  ([dec_bn, gru_inference_state_input])\n",
    "\n",
    "    \n",
    "     dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
    "     dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n",
    "\n",
    "     dec_model = Model([dec_inp, gru_inference_state_input],\n",
    "                                   [dense_out, gru_state_out],name=\"Decoder-Model\")\n",
    "\n",
    "    \n",
    "     return enc_model, dec_model, model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "     \n",
    "     num_input_tokens  = 1000\n",
    "     num_output_tokens  = 2000\n",
    "     input_seq_len = 10\n",
    "     output_seq_len = 20\n",
    "     latent_dim = 30\n",
    "    \n",
    "     enc_model, dec_model, model = build_model (num_input_tokens, num_output_tokens, input_seq_len,output_seq_len, latent_dim) \n",
    "     print(model.summary())\n",
    "\n",
    "     print(enc_model.summary())\n",
    "     print(dec_model.summary())\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f834ef4-235e-4409-8e56-f72d6dbeb367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
