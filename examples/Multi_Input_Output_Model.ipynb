{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c0902ef-3782-40b2-8cde-3b7b9dc3ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder-Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Input-Layer1 (InputLayer)   [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " Input-Layer2 (InputLayer)   [(None, 30)]                 0         []                            \n",
      "                                                                                                  \n",
      " Embedding-Layer1 (Embeddin  (None, 20, 60)               6000      ['Input-Layer1[0][0]']        \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " Embedding-Layer2 (Embeddin  (None, 30, 60)               7200      ['Input-Layer2[0][0]']        \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " Encoder-Batchnorm-1 (Batch  (None, 20, 60)               240       ['Embedding-Layer1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Encoder-Batchnorm-2 (Batch  (None, 30, 60)               240       ['Embedding-Layer2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, 60),                 29040     ['Encoder-Batchnorm-1[0][0]'] \n",
      "                              (None, 60),                                                         \n",
      "                              (None, 60)]                                                         \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               [(None, 60),                 29040     ['Encoder-Batchnorm-2[0][0]'] \n",
      "                              (None, 60),                                                         \n",
      "                              (None, 60)]                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 60)                   0         ['lstm_6[0][0]',              \n",
      " OpLambda)                                                           'lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 60)                   0         ['lstm_6[0][1]',              \n",
      " OpLambda)                                                           'lstm_7[0][1]']              \n",
      "                                                                                                  \n",
      " Final-Output-Dense1 (Dense  (None, 4)                    244       ['tf.__operators__.add_6[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " Final-Output-Dense2 (Dense  (None, 6)                    366       ['tf.__operators__.add_7[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 72370 (282.70 KB)\n",
      "Trainable params: 72130 (281.76 KB)\n",
      "Non-trainable params: 240 (960.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, BatchNormalization,  LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from preproc import build_vocabulary, Vectorizer \n",
    "\n",
    "input_vec_len1 = 20\n",
    "input_vec_len2 = 30 \n",
    "\n",
    "num_labels1  = 4\n",
    "num_labels2  = 6 \n",
    "\n",
    "latent_dim  = 60 \n",
    "num_tokens1 = 100\n",
    "num_tokens2 = 120 \n",
    "\n",
    "\n",
    "def get_model ():\n",
    "    \n",
    "    input1  = Input(shape=(input_vec_len1,),  name='Input-Layer1')\n",
    "    x1 = Embedding(num_tokens1, latent_dim, name='Embedding-Layer1', mask_zero=False) (input1)\n",
    "    x1 = BatchNormalization(name='Encoder-Batchnorm-1')(x1)\n",
    "    y1, h1, c1 =  LSTM(latent_dim, return_state=True) (x1)\n",
    "\n",
    "    input2  = Input(shape=(input_vec_len2,),  name='Input-Layer2')\n",
    "    x2 = Embedding(num_tokens2, latent_dim, name='Embedding-Layer2', mask_zero=False) (input2)\n",
    "    x2 = BatchNormalization(name='Encoder-Batchnorm-2')(x2)\n",
    "    y2, h2, c2 =  LSTM(latent_dim, return_state=True) (x2)\n",
    "\n",
    "    y = y1 + y1\n",
    "    h = h1 + h2  \n",
    "    \n",
    "    final_output1 = Dense(num_labels1, activation='softmax', name='Final-Output-Dense1')(y)\n",
    "    final_output2 = Dense(num_labels2, activation='softmax', name='Final-Output-Dense2')(h)\n",
    "\n",
    "    model = Model(inputs = [input1,input2], outputs=[final_output1,final_output2], name='Encoder-Model')\n",
    "    return model \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    M = get_model ()\n",
    "    print(M.summary())\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9bda4-c173-4320-8d8a-4da4bdf17c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
