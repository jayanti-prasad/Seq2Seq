{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d8f16e-2b55-4805-8460-70aa26fc001e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input-Layer (InputLayer)    [(None, 10)]              0         \n",
      "                                                                 \n",
      " Embedding-Layer (Embedding  (None, 10, 60)            1551120   \n",
      " )                                                               \n",
      "                                                                 \n",
      " Encoder-Batchnorm-1 (Batch  (None, 10, 60)            240       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               [(None, 60),              29040     \n",
      "                              (None, 60),                        \n",
      "                              (None, 60)]                        \n",
      "                                                                 \n",
      " Final-Output-Dense (Dense)  (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1580522 (6.03 MB)\n",
      "Trainable params: 1580402 (6.03 MB)\n",
      "Non-trainable params: 120 (480.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Inference-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input-Layer (InputLayer)    [(None, 60)]              0         \n",
      "                                                                 \n",
      " Embedding-Layer (Embedding  multiple                  1551120   \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1551120 (5.92 MB)\n",
      "Trainable params: 1551120 (5.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(100, 1, 60)\n",
      "[[[-0.01400259  0.01811411  0.03053967 ...  0.00095654 -0.02678878\n",
      "   -0.04810432]]\n",
      "\n",
      " [[-0.01346964  0.01215407  0.027944   ... -0.00528973  0.01118382\n",
      "   -0.01787804]]\n",
      "\n",
      " [[ 0.02750695 -0.01058788 -0.04904507 ... -0.05792885 -0.03555959\n",
      "    0.01945465]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01053241 -0.02775332 -0.00613628 ... -0.01218314  0.00184033\n",
      "    0.00419484]]\n",
      "\n",
      " [[-0.0110849  -0.01733604 -0.05167708 ... -0.04115445  0.03592412\n",
      "    0.07391305]]\n",
      "\n",
      " [[ 0.00200025  0.02438647 -0.03529366 ... -0.02886732  0.01455689\n",
      "    0.00352576]]]\n",
      "808/808 [==============================] - 1s 640us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import  Input\n",
    "from tensorflow.keras.models import Model, load_model \n",
    "\n",
    "\n",
    "class Text2Vec:\n",
    "    def __init__(self, model_path, df_vocab):\n",
    "        latent_dim = 60 \n",
    "        self.df_vocab = df_vocab \n",
    "        model = load_model(model_path + os.sep +'model.hdf5')\n",
    "        print(model.summary())\n",
    "\n",
    "        input_data   = Input(shape=(latent_dim,), name='Input-Layer')\n",
    "        output_data  = model.get_layer('Embedding-Layer')  (input_data) \n",
    "        \n",
    "        self.infr_model = Model (input_data, output_data,name='Inference-Model')\n",
    "        print(self.infr_model.summary())\n",
    "\n",
    "        ids = [i for i in range (0, len (df_vocab))]\n",
    "        keys = df_vocab['word'].to_list()\n",
    "        self.word2id = dict (zip (keys, ids))\n",
    "        \n",
    "        input_data = np.random.randint (11,2344,[100,1])\n",
    "        out = self.infr_model.predict (input_data)\n",
    "        \n",
    "        print(out.shape)\n",
    "        print(out)\n",
    "\n",
    "    \n",
    "    def text2vec (self, text):\n",
    "\n",
    "        tokens = text.split(\" \")\n",
    "        vec = [self.word2id[token] for token in tokens if token in tokens]\n",
    "        vec = self.infr_model.predict (vec)\n",
    "        \n",
    "        return vec \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model_root=\"tmp_lstm\"\n",
    "    model_path = model_root + os.sep + \"trained_model\"\n",
    "\n",
    "    df_vocab = pd.read_csv(model_root+os.sep + \"vocab.csv\")\n",
    "    df_vocab = df_vocab [ df_vocab['count'] > 10].dropna()\n",
    "\n",
    "    T = Text2Vec (model_path, df_vocab)\n",
    "\n",
    "    words = df_vocab['word'].to_list()\n",
    "    words = [ str(w) for w in words]  \n",
    "\n",
    "    text = \" \".join (words)\n",
    "    vecs = T.text2vec (text)\n",
    "\n",
    "    dF = pd.DataFrame (columns=[i for i  in range (0, 60)])\n",
    "    for i in range (0, len(words)):\n",
    "        dF.loc[i] = vecs[i,:] \n",
    "\n",
    "    dF.index = words \n",
    "    \n",
    "    dF.to_csv(model_root + os.sep + \"word_vecs.csv\")                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5eb798-1b2f-48f8-b51b-502fe6e3b954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25852 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406d63c-86b9-4f38-861f-356c377a2dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
